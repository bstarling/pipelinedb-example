version: '3'
networks:
  pipeline:
services:
  zookeeper:
    image: zookeeper:3.4.9
    restart: unless-stopped
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zookeeper:2888:3888
    networks:
      - pipeline
    ports:
      - 2181:2181

  kafka:
    image: confluentinc/cp-kafka:4.0.0
    environment:
      # add the entry "127.0.0.1    kafka" to your /etc/hosts file
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_DIRS: ./vols/kafka-data/data

    depends_on:
      - zookeeper
    networks:
      - pipeline
    ports:
      - 9092:9092
  
  pipelinedb:
    build:
      context: "."
    environment:
      POSTGRES_USER: pipeline
      POSTGRES_PASSWORD: changeme
      POSTGRES_DB: pipelinedb
    ports:
      - 15432:5432

    volumes:
      - ./vols/postgres-data:/var/lib/postgresql/data
    networks:
      - pipeline